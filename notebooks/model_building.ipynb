{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6f6f4a",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e39adef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467b323",
   "metadata": {},
   "source": [
    "### Positional Encoding for movie sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ab7be9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float=0.1, max_len: int=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        positions = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2)*(-math.log(10000.0)/d_model))\n",
    "        \n",
    "        pe = torch.zeros(max_len,1,d_model)\n",
    "\n",
    "        pe[:, 0, 0::2] = torch.sin(positions * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(positions * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "608b225a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5])\n",
      "torch.Size([1, 5, 2])\n",
      "torch.Size([1, 5, 2])\n"
     ]
    }
   ],
   "source": [
    "pe = PositionalEncoding(2)\n",
    "x = torch.tensor([[0,0,0,0,0]])\n",
    "print(x.shape)\n",
    "e = nn.Embedding(10,2)\n",
    "y_e = e(x)\n",
    "print(y_e.shape)\n",
    "y=pe(y_e)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c3d322",
   "metadata": {},
   "source": [
    "### Generate embeddings for batch of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fd7a91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from typing import Tuple\n",
    "\n",
    "class MovieEmbeddings(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int,\n",
    "                 hidden_size: int,\n",
    "                 num_list_features: int,\n",
    "                 num_scalar_features: int,\n",
    "                 n_genres: int, \n",
    "                 n_production_companies: int,\n",
    "                 n_production_countries: int,\n",
    "                 n_spoken_languages: int,\n",
    "                 n_words: int):\n",
    "        super().__init__()\n",
    "        self.genres_embedding = nn.EmbeddingBag(n_genres, d_model*2, mode='mean')\n",
    "        self.prod_comp_embedding = nn.EmbeddingBag(n_production_companies, d_model, mode='mean')\n",
    "        self.prod_cont_embedding = nn.EmbeddingBag(n_production_countries, d_model, mode='mean')\n",
    "        self.lang_embedding = nn.EmbeddingBag(n_spoken_languages, d_model, mode='mean')\n",
    "        self.word_embedding = nn.EmbeddingBag(n_words, d_model*4, mode='mean')\n",
    "        self.fc = nn.Linear(d_model*(10+num_list_features)+num_scalar_features,hidden_size)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self) -> None:\n",
    "        nn.init.xavier_uniform_(self.genres_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.prod_comp_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.prod_cont_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.lang_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.word_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def _prepare_embedding_inputs(self, list_of_lists) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        flat_list = []\n",
    "        offsets = [0]\n",
    "        for sublist in list_of_lists:\n",
    "            flat_list.extend(sublist)\n",
    "            offsets.append(offsets[-1] + len(sublist))\n",
    "        offsets = offsets[:-1]  # Remove last cumulative sum\n",
    "        offsets = torch.tensor(offsets, dtype=torch.long)\n",
    "        flat_list = torch.tensor(flat_list, dtype=torch.long)\n",
    "        return flat_list, offsets   \n",
    "\n",
    "    def forward(self, row: pl.DataFrame) -> torch.Tensor:\n",
    "        genres, genres_offsets = self._prepare_embedding_inputs(row['genres_idx'])\n",
    "        genres_e = self.genres_embedding(genres, genres_offsets)\n",
    "\n",
    "        comp, comp_offsets = self._prepare_embedding_inputs(row['production_companies_idx'])\n",
    "        comp_e = self.prod_comp_embedding(comp, comp_offsets)\n",
    "\n",
    "        cont, cont_offsets = self._prepare_embedding_inputs(row['production_countries_idx'])\n",
    "        cont_e = self.prod_cont_embedding(cont, cont_offsets)\n",
    "\n",
    "        lang, lang_offsets = self._prepare_embedding_inputs(row['spoken_languages_idx'])\n",
    "        lang_e = self.lang_embedding(lang, lang_offsets)\n",
    "\n",
    "        kw, kw_offsets = self._prepare_embedding_inputs(row['keywords_idx'])\n",
    "        kw_e = self.word_embedding(kw, kw_offsets)\n",
    "\n",
    "        tag, tag_offsets = self._prepare_embedding_inputs(row['tagline_idx'])\n",
    "        tag_e = self.word_embedding(tag, tag_offsets)\n",
    "\n",
    "        ov, ov_offsets = self._prepare_embedding_inputs(row['overview_idx'])\n",
    "        ov_e = self.word_embedding(ov, ov_offsets)\n",
    "\n",
    "        # Scalar features as tensors (ensure shape is [batch_size, 1])\n",
    "        revenue = torch.tensor(row[\"revenue\"], dtype=torch.float32).unsqueeze(1)\n",
    "        budget = torch.tensor(row[\"budget\"], dtype=torch.float32).unsqueeze(1)\n",
    "        runtime = torch.tensor(row[\"runtime\"], dtype=torch.float32).unsqueeze(1)\n",
    "        adult_idx = torch.tensor(row[\"adult_idx\"], dtype=torch.bool).unsqueeze(1)\n",
    "        vote_average = torch.tensor(row[\"vote_average\"], dtype=torch.float32).unsqueeze(1)\n",
    "        vote_count = torch.tensor(row[\"vote_count\"], dtype=torch.float32).unsqueeze(1)\n",
    "        popularity = torch.tensor(row[\"popularity\"], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "        # Concatenate all embeddings and scalar features\n",
    "        master_embedding = torch.cat([\n",
    "            genres_e,\n",
    "            comp_e,\n",
    "            cont_e,\n",
    "            lang_e,\n",
    "            kw_e,\n",
    "            tag_e,\n",
    "            ov_e,\n",
    "            revenue,\n",
    "            budget,\n",
    "            runtime,\n",
    "            adult_idx,\n",
    "            vote_average,\n",
    "            vote_count,\n",
    "            popularity\n",
    "        ], dim=1)\n",
    "\n",
    "        return self.fc(master_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "30453605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 18102672\n",
      "torch.Size([10, 256])\n",
      "tensor([[-1831.9744,  -866.2841, -2882.7822,  ...,   242.2773, -3159.7954,\n",
      "         -2309.8333],\n",
      "        [-1665.1652,  -841.4111, -2762.7041,  ...,   210.1431, -3007.7551,\n",
      "         -2248.9331],\n",
      "        [-1839.4342,  -632.6804, -2498.7393,  ...,   245.2319, -2732.8325,\n",
      "         -1841.5848],\n",
      "        ...,\n",
      "        [-1010.3897,  -944.6721, -2421.1853,  ...,   116.8286, -2649.2502,\n",
      "         -2254.8867],\n",
      "        [-1520.3438,  -588.8050, -2210.5342,  ...,   201.7019, -2393.4956,\n",
      "         -1680.5638],\n",
      "        [-1059.3677,  -875.0412, -2221.3069,  ...,   133.6470, -2497.7415,\n",
      "         -2035.9862]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "len_genres = 21\n",
    "len_prod_comp = 45546\n",
    "len_prod_cont = 201\n",
    "len_langs = 164\n",
    "len_words = 270246\n",
    "movies_prepped = pl.read_parquet('../data/processed/output.parquet')\n",
    "\n",
    "me = MovieEmbeddings(16,256,7,7,len_genres,len_prod_comp,len_prod_cont,len_langs,len_words)\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in me.parameters() if p.requires_grad)}\")\n",
    "y = me(movies_prepped[:10])\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4242edf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
