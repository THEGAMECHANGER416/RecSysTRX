{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf6f6f4a",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e39adef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a467b323",
   "metadata": {},
   "source": [
    "### Positional Encoding for movie sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7be9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float=0.1, max_len: int=5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        positions = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0,d_model,2)*(-math.log(10000.0)/d_model))\n",
    "        \n",
    "        pe = torch.zeros(max_len,1,d_model)\n",
    "\n",
    "        pe[:, 0, 0::2] = torch.sin(positions * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(positions * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608b225a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pe = PositionalEncoding(2)\n",
    "x = torch.tensor([[0,0,0,0,0]])\n",
    "print(x.shape)\n",
    "e = nn.Embedding(10,2)\n",
    "y_e = e(x)\n",
    "print(y_e.shape)\n",
    "y=pe(y_e)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c3d322",
   "metadata": {},
   "source": [
    "### Generate embeddings for batch of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd7a91a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from typing import Tuple\n",
    "\n",
    "class MovieEmbeddings(nn.Module):\n",
    "    def __init__(self, \n",
    "                 d_model: int,\n",
    "                 hidden_size: int,\n",
    "                 num_list_features: int,\n",
    "                 num_scalar_features: int,\n",
    "                 n_genres: int, \n",
    "                 n_production_companies: int,\n",
    "                 n_production_countries: int,\n",
    "                 n_spoken_languages: int,\n",
    "                 n_words: int):\n",
    "        super().__init__()\n",
    "        self.genres_embedding = nn.EmbeddingBag(n_genres, d_model*2, mode='mean')\n",
    "        self.prod_comp_embedding = nn.EmbeddingBag(n_production_companies, d_model, mode='mean')\n",
    "        self.prod_cont_embedding = nn.EmbeddingBag(n_production_countries, d_model, mode='mean')\n",
    "        self.lang_embedding = nn.EmbeddingBag(n_spoken_languages, d_model, mode='mean')\n",
    "        self.word_embedding = nn.EmbeddingBag(n_words, d_model*4, mode='mean')\n",
    "        self.fc = nn.Linear(d_model*(10+num_list_features)+num_scalar_features,hidden_size)\n",
    "        self._init_weights()\n",
    "\n",
    "    def _init_weights(self) -> None:\n",
    "        nn.init.xavier_uniform_(self.genres_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.prod_comp_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.prod_cont_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.lang_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.word_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.fc.weight)\n",
    "        nn.init.zeros_(self.fc.bias)\n",
    "\n",
    "    def _prepare_embedding_inputs(self, list_of_lists) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        flat_list = []\n",
    "        offsets = [0]\n",
    "        for sublist in list_of_lists:\n",
    "            flat_list.extend(sublist)\n",
    "            offsets.append(offsets[-1] + len(sublist))\n",
    "        offsets = offsets[:-1]  # Remove last cumulative sum\n",
    "        offsets = torch.tensor(offsets, dtype=torch.long)\n",
    "        flat_list = torch.tensor(flat_list, dtype=torch.long)\n",
    "        return flat_list, offsets   \n",
    "\n",
    "    def forward(self, row: pl.DataFrame) -> torch.Tensor:\n",
    "        genres, genres_offsets = self._prepare_embedding_inputs(row['genres_idx'])\n",
    "        genres_e = self.genres_embedding(genres, genres_offsets)\n",
    "\n",
    "        comp, comp_offsets = self._prepare_embedding_inputs(row['production_companies_idx'])\n",
    "        comp_e = self.prod_comp_embedding(comp, comp_offsets)\n",
    "\n",
    "        cont, cont_offsets = self._prepare_embedding_inputs(row['production_countries_idx'])\n",
    "        cont_e = self.prod_cont_embedding(cont, cont_offsets)\n",
    "\n",
    "        lang, lang_offsets = self._prepare_embedding_inputs(row['spoken_languages_idx'])\n",
    "        lang_e = self.lang_embedding(lang, lang_offsets)\n",
    "\n",
    "        kw, kw_offsets = self._prepare_embedding_inputs(row['keywords_idx'])\n",
    "        kw_e = self.word_embedding(kw, kw_offsets)\n",
    "\n",
    "        tag, tag_offsets = self._prepare_embedding_inputs(row['tagline_idx'])\n",
    "        tag_e = self.word_embedding(tag, tag_offsets)\n",
    "\n",
    "        ov, ov_offsets = self._prepare_embedding_inputs(row['overview_idx'])\n",
    "        ov_e = self.word_embedding(ov, ov_offsets)\n",
    "\n",
    "        # Scalar features as tensors (ensure shape is [batch_size, 1])\n",
    "        revenue = torch.tensor(row[\"revenue\"], dtype=torch.float32).unsqueeze(1)\n",
    "        budget = torch.tensor(row[\"budget\"], dtype=torch.float32).unsqueeze(1)\n",
    "        runtime = torch.tensor(row[\"runtime\"], dtype=torch.float32).unsqueeze(1)\n",
    "        adult_idx = torch.tensor(row[\"adult_idx\"], dtype=torch.bool).unsqueeze(1)\n",
    "        vote_average = torch.tensor(row[\"vote_average\"], dtype=torch.float32).unsqueeze(1)\n",
    "        vote_count = torch.tensor(row[\"vote_count\"], dtype=torch.float32).unsqueeze(1)\n",
    "        popularity = torch.tensor(row[\"popularity\"], dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "        # Concatenate all embeddings and scalar features\n",
    "        master_embedding = torch.cat([\n",
    "            genres_e,\n",
    "            comp_e,\n",
    "            cont_e,\n",
    "            lang_e,\n",
    "            kw_e,\n",
    "            tag_e,\n",
    "            ov_e,\n",
    "            revenue,\n",
    "            budget,\n",
    "            runtime,\n",
    "            adult_idx,\n",
    "            vote_average,\n",
    "            vote_count,\n",
    "            popularity\n",
    "        ], dim=1)\n",
    "\n",
    "        return self.fc(master_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dfba026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = torch.load('../data/all_vocabs.pth')\n",
    "\n",
    "user_vocab = vocabs[\"user_vocab\"]\n",
    "movie_vocab = vocabs[\"movie_vocab\"]\n",
    "genres_vocab = vocabs[\"genres_vocab\"]\n",
    "prod_comp_vocab = vocabs[\"prod_comp_vocab\"]\n",
    "prod_countries_vocab = vocabs[\"prod_countries_vocab\"]\n",
    "languages_vocab = vocabs[\"languages_vocab\"]\n",
    "words_vocab = vocabs[\"words_vocab\"]\n",
    "movie_vocab_stoi = movie_vocab.get_stoi()\n",
    "user_vocab_stoi = user_vocab.get_stoi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30453605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 18102672\n",
      "torch.Size([10, 256])\n",
      "tensor([[ 4347.0571,  2064.8047,  1902.0768,  ...,  3807.1909, -2614.1748,\n",
      "          -671.3229],\n",
      "        [ 4014.5408,  2019.2638,  1782.0667,  ...,  3566.9268, -2405.8521,\n",
      "          -626.9221],\n",
      "        [ 4107.3535,  1571.4141,  1645.0946,  ...,  3552.3320, -2475.6802,\n",
      "          -632.4916],\n",
      "        ...,\n",
      "        [ 2912.2559,  2153.8618,  1563.6954,  ...,  2677.5276, -1732.4044,\n",
      "          -457.1087],\n",
      "        [ 3454.8982,  1460.3892,  1426.9508,  ...,  3037.6448, -2076.8008,\n",
      "          -549.8853],\n",
      "        [ 2934.0432,  1941.7190,  1530.2401,  ...,  2573.1045, -1762.0673,\n",
      "          -430.7871]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "movies_prepped = pl.read_parquet('../data/processed/output.parquet')\n",
    "\n",
    "me = MovieEmbeddings(16,256,7,7,len(genres_vocab),len(prod_comp_vocab),len(prod_countries_vocab),len(languages_vocab),len(words_vocab))\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in me.parameters() if p.requires_grad)}\")\n",
    "y = me(movies_prepped[:10])\n",
    "print(y.shape)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3967dc7",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4242edf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = pl.read_parquet('../data/processed/train.parquet').to_numpy()\n",
    "test_data_raw = pl.read_parquet('../data/processed/test.parquet').to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41c4fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "class MovieSeqDataset(Dataset):\n",
    "    def __init__(self, data, movie_vocab_stoi, user_vocab_stoi):\n",
    "        self.data = data\n",
    "        self.movie_vocab_stoi = movie_vocab_stoi\n",
    "        self.user_vocab_stoi = user_vocab_stoi\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        user, movie_sequence, rating_sequence = self.data[idx]\n",
    "        movie_data = [self.movie_vocab_stoi.get(item,movie_vocab_stoi['<unk>']) for item in movie_sequence]\n",
    "        user_data = self.user_vocab_stoi[user]\n",
    "        return torch.tensor(movie_data), torch.tensor(user_data), torch.tensor(rating_sequence)\n",
    "    \n",
    "def collate_batch(batch):\n",
    "    movie_list = [item[0] for item in batch]\n",
    "    user_list = [item[1] for item in batch]\n",
    "    rating_list = [item[2] for item in batch]\n",
    "    return pad_sequence(movie_list, padding_value=movie_vocab_stoi['<unk>'], batch_first=True), torch.stack(user_list), pad_sequence(rating_list, padding_value=3, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1cbd136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataset = MovieSeqDataset(train_data_raw, movie_vocab_stoi, user_vocab_stoi)\n",
    "val_dataset = MovieSeqDataset(test_data_raw, movie_vocab_stoi, user_vocab_stoi)\n",
    "\n",
    "train_iter = DataLoader(train_dataset, batch_size=BATCH_SIZE,shuffle=True, collate_fn=collate_batch)\n",
    "val_iter = DataLoader(val_dataset, batch_size=BATCH_SIZE,shuffle=False, collate_fn=collate_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff285e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5]) torch.Size([16]) torch.Size([16, 5])\n"
     ]
    }
   ],
   "source": [
    "for i, (movie_data, user_data, ratings_data) in enumerate(train_iter):\n",
    "    print(movie_data.shape, user_data.shape, ratings_data.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
